{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abae7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soham\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a71c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "TOTAL_NODES = 26  # Size of node space (from G)\n",
    "HIDDEN_DIM = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "class EdgeDecoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_channels * 2, 1)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        edge_feats = torch.cat([z[src], z[dst]], dim=1)\n",
    "        return self.linear(edge_feats).squeeze()\n",
    "\n",
    "class GraphCompletionModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GCNEncoder(in_channels, hidden_channels)\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, candidate_edges):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        scores = self.decoder(z, candidate_edges)\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32a61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_non_edges(num_nodes, existing_edges, num_samples):\n",
    "    existing_set = set(existing_edges)\n",
    "    all_possible = [(i, j) for i in range(num_nodes) for j in range(num_nodes) if i != j]\n",
    "    candidates = list(set(all_possible) - existing_set)\n",
    "    return random.sample(candidates, min(num_samples, len(candidates)))\n",
    "\n",
    "def compute_accuracy(scores, labels, threshold=0.5):\n",
    "    preds = (torch.sigmoid(scores) > threshold).float()\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ed415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_supervised_data(G_prime_list, G_double_prime_LOL, total_nodes):\n",
    "    data = []\n",
    "    for i in range(len(G_prime_list)):\n",
    "        G_prime = G_prime_list[i]\n",
    "        G_double_primes = G_double_prime_LOL[i]\n",
    "\n",
    "        true_edges = list(map(tuple, G_prime.edge_index.t().tolist()))\n",
    "\n",
    "        for G_double_prime in G_double_primes:\n",
    "            observed_edges = list(map(tuple, G_double_prime.edge_index.t().tolist()))\n",
    "            positive_edges = [e for e in true_edges if e not in observed_edges]\n",
    "            negative_edges = sample_non_edges(total_nodes, true_edges, len(positive_edges))\n",
    "\n",
    "            data.append((G_double_prime, positive_edges, negative_edges))\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df967a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, total_nodes, epochs=50, lr=0.01, device='cpu'):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for G_double_prime, pos_edges, neg_edges in train_data:\n",
    "            x = torch.eye(total_nodes).to(device)\n",
    "            edge_index = G_double_prime.edge_index.to(device)\n",
    "            candidate_edges = torch.tensor(pos_edges + neg_edges, dtype=torch.long).t().contiguous().to(device)\n",
    "            labels = torch.tensor([1]*len(pos_edges) + [0]*len(neg_edges), dtype=torch.float).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scores = model(x, edge_index, candidate_edges)\n",
    "            loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_val_loss = 0\n",
    "            total_val_acc = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for G_double_prime, pos_edges, neg_edges in test_data:\n",
    "                x = torch.eye(total_nodes).to(device)\n",
    "                edge_index = G_double_prime.edge_index.to(device)\n",
    "                candidate_edges = torch.tensor(pos_edges + neg_edges, dtype=torch.long).t().contiguous().to(device)\n",
    "                labels = torch.tensor([1]*len(pos_edges) + [0]*len(neg_edges), dtype=torch.float).to(device)\n",
    "\n",
    "                scores = model(x, edge_index, candidate_edges)\n",
    "                val_loss = F.binary_cross_entropy_with_logits(scores, labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "                total_val_acc += compute_accuracy(scores, labels) * len(labels)\n",
    "                total_samples += len(labels)\n",
    "\n",
    "            print(f\"[Epoch {epoch+1}] Train Loss: {total_loss:.4f} | Val Loss: {total_val_loss:.4f} | Val Acc: {total_val_acc/total_samples:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c841a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_pipeline(G, G_prime_list, G_double_prime_LOL):\n",
    "    data = prepare_supervised_data(G_prime_list, G_double_prime_LOL, TOTAL_NODES)\n",
    "    train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = GraphCompletionModel(in_channels=TOTAL_NODES, hidden_channels=HIDDEN_DIM)\n",
    "    train_model(model, train_set, test_set, TOTAL_NODES, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be382bff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Main_graph_withNodeFeats.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpkl\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMain_graph_withNodeFeats.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     G \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Main_graph_withNodeFeats.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"Main_graph_withNodeFeats.pkl\", \"rb\") as f:\n",
    "    G = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2f8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
